{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Intro to Keras\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Slides\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Slides available from (this will redirect to my github repo.):\n\n<span class=\"underline\">[https://git.io/knu-slides-2019](https://git.io/knu-slides-2019)</span>\n\n-   Other Resources:\n    -   Keras documentation: <span class=\"underline\">[http://keras.io/](http://keras.io/)</span>\n    -   Tensorflow's guide to Keras: <span class=\"underline\">[https://www.tensorflow.org/guide/keras](https://www.tensorflow.org/guide/keras)</span>\n    -   Another tutorial presentation:\n        <span class=\"underline\">[https://uwaterloo.ca/data-science/sites/ca.data-science/files/uploads/files/keras_tutorial.pdf](https://uwaterloo.ca/data-science/sites/ca.data-science/files/uploads/files/keras_tutorial.pdf)</span>\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Goals\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   If you're already a deep learning master, not the talk for you!\n-   Get up and running quickly with Deep Learning\n    -   In particular, the goal is to build neural networks you can take home today!\n-   Therefore, use *Keras* to get up and running quickly\n-   Outline of the session:\n    -   Basic Usage of Keras (Iris)\n    -   Convolutional Neural Net in Keras (MNIST)\n    -   GANs (using MNIST)\n-   For this lecture, I recommend using *google colaboratory*\n    -   Machine learning education and research tool setup by google, all\n        the packages are installed, just need a google account to sign in\n\n[https://colab.research.google.com](https://colab.research.google.com)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Dependencies\n\n"]},{"cell_type":"markdown","metadata":{},"source":["*However,*\n\nIf you want to follow along with a local setup:\n\nWith python and pip installed, you can pull the dependencies by pip\ninstalling (you might need to add \\`&#x2013;user\\` to the end of the command\nlines):\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Optional, setup a separate virtualenv to keep everything clean\nvirtualenv ENV\nsource ENV/bin/activate\n# Download dependencies, tensorflow will be the CPU version\npip install matplotlib tensorflow seaborn scikit-learn h5py jupyter\n# Then you could start a notebook\njupyter notebook"]},{"cell_type":"markdown","metadata":{},"source":["For a GPU tensorflow, usually best to build yourself (out of scope)\n\n-   Now, let's setup a new workspace\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Google Colab / Jupyter Basic Usage\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   <span class=\"underline\">[https://colab.research.google.com/notebook](https://colab.research.google.com/notebook)</span>\n-   Offers free jupyter-notebook-as-a-service in the cloud\n    -   Even offers free access to cloud-based GPUs\n-   Has all the packages we'll need for today pre-installed\n-   Demo\n    -   Basic jupyter usage\n\n    !ls # execute external commands\n    import os\n    ?os # help at your fingertips\n    pi = 3.14159 # interpreter persists over cells\n    pi*2\n    \n    def area(radius):\n        return pi*radius**2\n    \n    area(1)\n    \n    # inline plotting\n    import numpy as np\n    import matplotlib.pyplot as plt\n    \n    x = np.linspace(-3.14, 3.14, 100)\n    y = np.sin(x)\n    plt.plot(x, y)\n    plt.show()\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Keras\n\n"]},{"cell_type":"markdown","metadata":{},"source":["![img](keras-logo-small-wb.png)\n\n![img](tensorflow-logo.png)\n\n-   Deep learning framework built by Google engineer Fran√ßois Chollet\n-   High-level interface built allowing eg Theano or Tensorflow as a backend\n    -   Has been accepted into mainline Tensorflow, so always accessible there\n-   Library written in python, user-friendly interface\n-   Easy to get started building networks\n-   Highly modular and easily expandable\n    -   Can drop down into the underlying library when complex/bespoke operations\n        are needed\n-   Quickly build and train serious models\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### imports\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Follow along either on the web-based service, or your own machine\n-   Lets pull in all the imports and definitions we'll need\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### :BMCOL:\n\n"]},{"cell_type":"markdown","metadata":{},"source":["    import h5py\n    import matplotlib\n    # matplotlib.use(\"AGG\")  # To batch graphics\n    import matplotlib.pyplot as plt\n    import os\n    import seaborn as sns\n    from sklearn.model_selection import train_test_split\n    import sklearn\n    import numpy as np\n    import tensorflow as tf\n    \n    keras = tf.keras\n    Sequential = keras.Sequential\n    Activation = keras.layers.Activation\n    Dense = keras.layers.Dense\n    LeakyReLU = keras.layers.LeakyReLU\n    BatchNormalization = keras.layers.BatchNormalization\n    Reshape = keras.layers.Reshape\n    UpSampling2D = keras.layers.UpSampling2D\n    Dropout = keras.layers.Dropout\n    Conv2D = keras.layers.Conv2D\n    MaxPooling2D = keras.layers.MaxPooling2D\n    Flatten = keras.layers.Flatten\n    SGD = keras.optimizers.SGD\n    mnist = keras.datasets.mnist\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## NN: Fisher's Irises\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Overarching Idea of (Supervised) Maching Learning\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Framework for Machine Learning: given a set of data, and set of\n    expected outputs (typically categories), build a system which learns\n    how to connect data to output\n-   Neural Network is one type, connect stacks of tensor operators with fixed linear and non-linear transformations\n-   Optimize transformation parameters so as to approximate expected outputs\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### The iris dataset and a basic network with Keras\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### :BMCOL:\n\n"]},{"cell_type":"markdown","metadata":{},"source":["![img](iris_petal_sepal.png)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["#### :BMCOL:\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Let's take a concrete example\n-   The iris dataset is a classic classification task, first studied by\n    Fisher in 1936.\n-   The goal is, given features measured from a particular\n    iris, classify it into one of three species\n    -   Iris setosa, virginica, versicolor.\n-   The variables are: Sepal width and length, petal width and length (all in cm).\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Iris dataset\n\n"]},{"cell_type":"markdown","metadata":{},"source":["We begin by loading the iris dataset, helpfully available from the\nseaborn pacakge, which also lets us create plots showing the\ncorrelations between the variables.\n\n    iris = sns.load_dataset(\"iris\")\n    iris.head()\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Iris Variables\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Lets view the basic variables we have. Setosa (blue) looks easily\nseparable by the petal length and width, but versicolor and virginica\nare a little tricky.\n\n    plot = sns.pairplot(iris, hue=\"species\")\n    plot.savefig('iris.png'); 'iris.png'\n\n[]()\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### The Logistic Function and Logistic Regression\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\\centering\n\n[logistic.pdf](logistic.pdf)\n\n-   The logistic (or sigmoid) function is defined as $f(x) = \\frac{1}{1+e^{-x}}$\n    -   Looks like a classic \"turn-on\" curve\n-   Concentrate on the case of two classes (cat/dog or electron/photon),\n    and ask what we want from a classifier output\n    -   We need to distinguish between the two classes using the output:\n    -   If the value is 0, it represents the classifier identifying one class (cat)\n    -   If its near 1, the classifier is identifies the other class (dog)\n    -   Thus, we need to transform the input variables into 1D, then pass through the logistic function\n-   This is a simple classification technique called *logistic regression*\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Some very simple examples for simple logistic regression\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Let's think about approximating some simple binary functions\n-   OR and AND gates\n    -   OR is 0 (red) if both input are 0, 1 (blue) otherwise\n    -   AND is 1 if both inputs are 1, 0 otherwise\n-   Can we find logistic function approximations for this?\n    -   That is, $f(x_1, x_2)$ returns approximately 1 or 0 at the indicated points \\pause\n-   Yes! Take the projection perpendicular to the line \\pause\n-   and have the logistic turn on at the line (in the 2D plane the\n    logistic function will turn on as a \"wave-front\" along the black\n    line shown)\n    -   e.g. $f(x_1, x_2) = \\sigma(2 x_1 + 2 x_2 - 1)$ for OR, $f(x_1, x_2) = \\sigma(2 x_1 + 2 x_2 - 3)$ for AND [&sigma; is our logistic function]\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Very simple example with issues for Logistic Regression\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Now consider the XOR gate: 1 if both inputs are the same, 0 otherwise\n-   The XOR gate can't be generated with a logistic function!\n-   Try it: no matter what line you draw, can't draw a logistic function\n    that turns on only the blue!\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### How to Fix: more logistic curves!\n\n"]},{"cell_type":"markdown","metadata":{},"source":["![img](XOR_turnon.png)\n\n-   Can fix by having 2 turn-on curves, one turning on either of the\n    blue points, then summing the result\n-   $f(x_1, x_2) = $ [$\\sigma(2 x_1 + 2 x_2 - 1)$](green) $+$ [$\\sigma(- 2 x_1 - 2 x_2 + 1)$](magenta)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### The Feed-Forward Neural Network:PROPERTIES:\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Consider the structure of what we just made\n    -   $y = f(x_1, x_2) = \\sigma(-1 + 2 x_1 + 2 x_2) + \\sigma(1 - 2 x_1 - 2 x_2)$\n-   Decompose the function into:\n    -   [the *input layer* of $\\hat{x}$](green),\n    -   [the *hidden layer* which calculates $h_i = \\beta_i\n            \\cdot x$ then passes if through the *activation function* &sigma;,\n        (called \"sigmoid\" in NN terms)](blue)\n        -   There is an extra $\\beta_0$, called the *bias*, which controls\n            how big the input into the node must be to activate; &sigma; is\n            implicit in the diagram\n    -   [the *output layer* which sums the results of the hidden layer and gives $y$](red)\n        -   $y = 0 + 1 \\cdot \\sigma(h_1) + 1 \\cdot \\sigma(h_2)$\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Feed-Forward Neural Network:PROPERTIES:\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   In general, we could have several input variables, and output variables\n-   In the case of classification, we would usually have a final\n    *softmax* applied to $\\hat{y}$, but could use any *activation* $\\varphi$ here also\n    -   *softmax* normalizes the output layer so it sums to 1: $f_k(x) = \\frac{e^{-y_k}}{\\sum_i e^{-y_i}}$\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Feed-Forward Neural Network:PROPERTIES:\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   We can even have several hidden layers\n    -   The previous layer acts the same as an *input layer* to the next\n        layer\n-   We call each node in the network a *neuron*\n-   The deep learning algorithms we will see later are just variations\n    on this theme, using more complicated transformations\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Universal Approximation Thereom\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\\small\nLet $\\varphi :\\mathbb {R} \\to \\mathbb {R}$ be a nonconstant,\nbounded, and continuous function. Let $I_{m}$ denote the\n$m$-dimensional unit hypercube $[0,1]^{m}$. The space of\nreal-valued continuous functions on $I_{m}$ is denoted by\n$C(I_{m})$. Then, given any $\\varepsilon >0$ and any function\n$f\\in C(I_{m})$, there exist an integer $N$, real constants\n$v_{i},b_{i}\\in \\mathbb {R}$ and real vectors $w_{i}\\in \\mathbb {R}\n^{m}$ for $i=1,\\ldots ,N$ such that we may define:\n$$F(x)=\\sum _{i=1}^{N}v_{i}\\varphi \\left(w_{i}^{T}x+b_{i}\\right)$$\nas an approximate realization of the function $f$; that is,\n$$|F(x)-f(x)|<\\varepsilon$$\nfor all $x\\in I_{m}$. In other words, functions of the form $F(x)$ are dense in $C(I_{m})$.\n\nThis still holds when replacing $I_{m}$ with any compact subset of $\\mathbb {R} ^{m}$. \n\n-   In brief: with a hidden layer (of enough nodes), any (sensible)\n    function $f : \\mathbb{R}^m \\to \\mathbb{R}$ can be approximated by\n    a feed-forward NN\n    -   Any (sensible) activation $\\varphi$ can work, not just &sigma;\n-   There is a simple, graphical proof for those who are interested: <span class=\"underline\">[http://neuralnetworksanddeeplearning.com/chap4.html](http://neuralnetworksanddeeplearning.com/chap4.html)</span>\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Neural Networks Overview\n\n"]},{"cell_type":"markdown","metadata":{},"source":["![img](neural_net.jpeg)\n\n-   Example shown: input vector $\\vec{x}$, goes through\n    $\\vec{y}_{hidden} = W\\vec{x} + \\vec{b}$, then $\\vec{y}_{output} =\n      \\sigma(\\vec{y}_{hidden})$ (&sigma; is some non-linear turn-on curve)\n-   I.e. hidden layer combines $\\vec{x}$ by some weights, then if the\n    weighted sum passes a threshold $\\vec{b}$, we turn on the output\n    (with the $\\sigma(x) = 1/(1+e^{-x})$ to gate the ops)\n-   Need to **train** the weight matrix $W$ and the bias vector $b$ and\n    optimize a \"loss\" function that represents a distance from the target output\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Backpropagation\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   The algorithm to train neural networks is called **backpropagation**\n-   Its essentially a gradient descent implemented taking the network\n    structure into account to speed up evaluation of the partials\n-   To apply gradient descent, need a function of a single variable, called the *loss*\n    -   $L(x_i|\\sigma) = \\sum_i |f(x_i | \\sigma) - y_i|^2$ for inputs $x_i$ and known output $y_i$\n-   We start with the parameters set to arbitrary values, usually picked from e.g. unit gaussian\n-   We run a forward pass through the network and calculate the loss\n-   Using the chain rule, calculate *all* the derivates backward from the loss to\n    the higher layers\n-   Propagate changes based on the gradient $\\Delta w_i = -\\eta \\frac{\\partial f}{\\partial w_i}$\n-   For more on how backpropagation works: <span class=\"underline\">[http://neuralnetworksanddeeplearning.com/chap2.html](http://neuralnetworksanddeeplearning.com/chap2.html)</span>\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Keras Networks\n\n"]},{"cell_type":"markdown","metadata":{},"source":["In order to classify the irises, we'll build a simple network in Keras.\n\n-   The basic network type in Keras is the `Sequential` model.\n-   The `Sequential` model builds a neural network by stacking layers \n    -   Keras also has a `Graph` model that allows arbitrary connections\n-   It builds up like lego, adding one layer on top of another and \n    connecting between the layers\n    -   Keras comes with a menagerie of pre-built layers for you to use.\n-   Interface to/from the model with numpy arrays\n\n![img](nn-1a.png)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Model\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Our model will be a simple NN with a single hidden layer\n-   We start by building a Sequential model and add a Dense (fully-connected) layer, with sigmoid activation\n-   Dense: standard layer, all inputs connect to all outputs: $\\hat{y} = W\\hat{x} + \\hat{b}$\n    -   `keras.layers.Dense(output_dim)`\n    -   Can also set the initalization, add an activation layer inline, add regularizers inline, etc.\n-   Activation: essentially acts as a switch for a given node, turns output on/off based on threshold\n    -   `keras.layers.Activation(` *type* `)`\n        -   Where *type* might be:\n    -   *sigmoid*: $f(x) = \\frac{1}{1 + e^{-x}}$\n    -   *tanh*: $f(x) = \\tanh{x} = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$\n    -   *relu*: $f(x) = \\mathrm{max}(0, x)$, 'rectified linear unit'\n    -   *softplus*: $f(x) =  \\ln{(1 + e^x)}$, smooth approx. to *relu*\n    -   *softmax*: $f_k(x) = \\frac{e^{-x_k}}{\\sum_i e^{-x_i}}$ for the $k$'th output, as last layer of categorical distribution, represents a probability distribution over the outputs\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Build a model: Python code\n\n"]},{"cell_type":"markdown","metadata":{},"source":["    # Build a model\n    model = Sequential()\n    \n    model.add(Dense(128, input_shape=(4,)))\n    model.add(Activation('sigmoid'))\n    # model.add(Dense(128))\n    # model.add(Activation('sigmoid'))\n    model.add(Dense(3))\n    model.add(Activation('softmax'))\n    \n    model.compile(optimizer='adam', loss='categorical_crossentropy', \n                  metrics=['accuracy'])\n    model.summary()\n\n    _________________________________________________________________\n    Layer (type)                 Output Shape              Param #   \n    =================================================================\n    dense_1 (Dense)              (None, 128)               640       \n    _________________________________________________________________\n    activation_1 (Activation)    (None, 128)               0         \n    _________________________________________________________________\n    dense_2 (Dense)              (None, 3)                 387       \n    _________________________________________________________________\n    activation_2 (Activation)    (None, 3)                 0         \n    =================================================================\n    Total params: 1,027\n    Trainable params: 1,027\n    Non-trainable params: 0\n    _________________________________________________________________\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### More on model building\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   When `add`'ing layers, keras takes care of input/output size details\n    -   Except for the input layer, which must be specified\n    -   We explicitly gave the network `(4,)` for our 4 input variables\n-   The final layer we make size 3 after a softmax activiation\n    -   This will output the network probability for each of the potential\n        iris classes as a numpy array \n        `(nsamples, (` $p_{setosa}$, $p_{virginica}$, $p_{versicolor}$ `))`\n-   We `compile` the model with an optimizer and loss function\n    -   The loss function will be minimized during the training phase\n-   We can give auxilliary `metrics` which will be calculated with the loss\n-   Keras automatically takes care of calculating derivatives through the network for the backprop phase\n-   We could be more explicit in creating the functions if we want more control over hyperparameters:\n\n    model.compile(loss=keras.losses.mean_squared_error, \n                  optimizer=keras.optimizers.SGD(lr=0.0005, momentum=0.9,\n                                                 nesterov=True))\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### More on model building\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Here we used the adam optimizer which automatically updates the step\nsizes used for parameter optimization, with a categorical\ncross-entropy loss, which measures $-\\sum_{i} t_i\\log{p_i}$ where\n$t_i$ is 1 for the true label and $p_i$ is the probability of the\n$i$th label assigned by the model. As the model assigns higher\nprobability to the correct label, the cross-entropy goes to 0.\n\n-   Other options to consider:\n    -   Activation: *sigmoid*, *softmax*, *linear*, *tanh*, *relu*, \\ldots\n    -   Optimizer: *SGD*, *RMSprop*, *Adagrad*, *Adadelta*, *Adam*, \\ldots\n    -   Loss: *categorical<sub>crossentropy</sub>*, *binary<sub>crossentropy</sub>*, *mean<sub>squared</sub><sub>error</sub>*, \\ldots\n\nReLU \\hfill sigmoid \\hfill tanh \\hfill softplus\n\n![img](relu.png) \n\n![img](sigmoid.png) \n\n![img](tanh.png) \n\n![img](softplus.png)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Model picture\n\n"]},{"cell_type":"markdown","metadata":{},"source":["If pydot is installed we can also output a picture of the network\n\n\\footnotesize\n\n    keras.utils.plot_model(model, to_file='iris_model.png')\n\n[]()\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Training Code\n\n"]},{"cell_type":"markdown","metadata":{},"source":["    # Split the variables to train, and the target\n    variables = iris.values[:, :4]\n    species = iris.values[:, 4]\n    \n    # One hot encode the species target\n    smap = {'setosa' : 0, 'versicolor' : 1, 'virginica' : 2}\n    species_enc = np.eye(3)[list(smap[s] for s in species)]\n    \n    # To show we are simply passing numpy arrays of the data\n    print(variables[0], species[0], species_enc[0])\n    \n    train_X, test_X, train_y, test_y = \\\n      train_test_split(variables, species_enc, train_size=0.8, random_state=0)\n    model.fit(train_X, train_y, epochs=15, batch_size=1, verbose=1)\n\n    [5.1 3.5 1.4 0.2] setosa [ 1.  0.  0.]\n    Epoch 1/15\n    120/120 [==============================] - 0s - loss: 0.2873 - acc: 0.9500     \n    \n    ...\n    \n    Epoch 15/15\n    120/120 [==============================] - 0s - loss: 0.1477 - acc: 0.9583\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Training\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Now we fit to the training data.\n-   We can set the number of `epochs`, `batch_size`, and `verbose`'ity\n    -   Epochs: number of training passes through the complete dataset\n    -   Batch size: number of datapoints to consider together when\n        updating the network\n-   We pass through the input data as a numpy array (nsamples, 4)\n-   We pass the output as (nsamples, 3) where for each sample one\n    of the positions is 1, corresponding to the correct class.\n-   We use the `np.eye` identity matrix creator to help us transform the raw species\n    information (which labels classes setosa, virginica, versicolor) to\n    the expected format\n    -   Setosa = `(1, 0, 0)`\n    -   Versicolor = `(0, 1, 0)`\n    -   Virginica = `(0, 0, 1)`\n-   We fit the model to a labelled dataset simply by calling `fit` with\n    the dataset `train_X` and the true labels `train_y`\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Evaluation\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   After running the model, we can `evaluate` how well it works on the\n    labelled *test* data we kept aside for *overfitting* evaluation\n    purposes.\n    -   Overfitting is when the model fits to the training set in a way\n        that doesn't generalize to unseen samples\n    -   One usually also has a separate *validation* set, use the *test*\n        set on a single model, choose a model you like, then check the\n        *hyperparameters* didn't cause bias by checking the *validation*\n\n    # The evaluation passes out the overall loss, \n    # as well as any other metrics you included \n    # when compiling the model\n    loss, accuracy = model.evaluate(test_X, test_y, verbose=0)\n    print(\"Loss={:.2f}\\nAccuracy = {:.2f}\".format(loss, accuracy))\n\n    Loss=0.11\n    Accuracy = 0.97\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Prediction\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   And we can ask the model to `predict` some unlabelled data\n    -   For illustration, we just use our test data, and compare the true\n        label against the 'prediction'\n    -   In the output, I stack the true answers (first rows), and the\n        prediction, which can basically be interpreted as the model's\n        probability for each category (second rows)\n\n    pred_y = model.predict(test_X)\n    print(np.stack([test_y, pred_y], axis=1)[:10])\n\n    [[[  0.00000000e+00   0.00000000e+00   1.00000000e+00]\n      [  2.63856982e-05   8.96630138e-02   9.10310626e-01]]\n    \n     [[  0.00000000e+00   1.00000000e+00   0.00000000e+00]\n      [  1.57812089e-02   9.63519156e-01   2.06995625e-02]]\n    \n     [[  1.00000000e+00   0.00000000e+00   0.00000000e+00]\n      [  9.96497989e-01   3.50204227e-03   1.25929889e-09]]\n    \n     [[  0.00000000e+00   0.00000000e+00   1.00000000e+00]\n      [  4.74178378e-05   1.32592529e-01   8.67359996e-01]]\n    \n     [[  1.00000000e+00   0.00000000e+00   0.00000000e+00]\n      [  9.87556934e-01   1.24430126e-02   1.36296467e-08]]\n    \n     [[  0.00000000e+00   0.00000000e+00   1.00000000e+00]\n      [  7.08267498e-06   3.83740403e-02   9.61618841e-01]]\n    \n     [[  1.00000000e+00   0.00000000e+00   0.00000000e+00]\n      [  9.89948869e-01   1.00511070e-02   9.48140944e-09]]\n    \n     [[  0.00000000e+00   1.00000000e+00   0.00000000e+00]\n      [  6.58096792e-03   8.90939236e-01   1.02479771e-01]]\n    \n     [[  0.00000000e+00   1.00000000e+00   0.00000000e+00]\n      [  4.53994563e-03   8.66963148e-01   1.28496900e-01]]\n    \n     [[  0.00000000e+00   1.00000000e+00   0.00000000e+00]\n      [  1.97829530e-02   9.56251919e-01   2.39650477e-02]]]\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## DNN: MNIST\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### MNIST digit recognition and Convolutional Networks\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Another, more recent, classic classification task.\n-   Given a 28x28 image of a handwritten digit, can you train a classifier to recognize the\n    numbers from 0 to 9?\n-   Keras has the ability to download the dataset and parse it into\n    numpy arrays. We use `to_categorical` to one hot encode the true\n    labels (which number did they write?) as for the irises\n\n    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n\n    from keras.utils.np_utils import to_categorical\n    # or to_categorical = tf.keras.utils.np_utils.to_categorical\n    \n    print(y_train[:4])\n    y_train_enc = np.eye(10)[y_train]\n    y_test_enc = to_categorical(y_test) # many ways to do the same thing\n    print(y_train_enc[:4])\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Examples\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   We can use `matplotlib.pyplot` to show a few example digits\n-   In *jupyter*, matplotlib results will show automatically, so you\n    don't need to print it out (or resize it for that matter)\n\n    print(x_train.shape, y_train_enc.shape)\n    plt.clf()\n    for i in range(6):\n        plt.subplot(1,6,i+1)\n        plt.imshow(x_train[i], cmap='gray')\n    \n    F = plt.gcf(); F.set_size_inches((14,2))\n    plt.savefig('mnist-examples.png');\n\n[]()\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Simple Network\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   We can start by simply trying a basic neural network as before.\n-   \\`Flatten\\` takes the 2D input and concatenates the rows together to a 1D form suitable for passing to a \\`Dense\\` layer.\n\n    model = Sequential()\n    model.add(Flatten(input_shape=(28,28)))\n    model.add(Dense(128))\n    model.add(Activation('sigmoid'))\n    model.add(Dense(128))\n    model.add(Activation('sigmoid'))\n    model.add(Dense(10))\n    model.add(Activation('softmax'))\n    \n    model.compile(optimizer='adam', loss='categorical_crossentropy', \n                  metrics=['accuracy'])\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Simple Network\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   And `fit` and `evaluate` as we did before\n\n    model.fit(x_train, y_train_enc, epochs=3, verbose=1)\n    loss, accuracy = model.evaluate(x_test, y_test_enc, verbose=0)\n    print(\"Loss={:.2f}\\nAccuracy = {:.2f}\".format(loss, accuracy))\n\n    Epoch 1/3\n    60000/60000 [==============================] - 4s - loss: 0.5373 - acc: 0.8531     \n    Epoch 2/3\n    60000/60000 [==============================] - 4s - loss: 0.3729 - acc: 0.8861     \n    Epoch 3/3\n    60000/60000 [==============================] - 4s - loss: 0.3207 - acc: 0.9020     \n    Loss=0.30\n    Accuracy = 0.91\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### A Convolutional Network\n\n"]},{"cell_type":"markdown","metadata":{},"source":["![img](NN_conv.png)\n\n-   One of the great advances in image classification in recent times\n-   We have some filter kernel $K$ of size $n \\times m$ which we apply\n    to every $n \\times m$ cell on the original image to create a new filtered\n    image.\n-   It has been seen that applying these in multiple layers of a network\n    can build up multiple levels of abstraction to classify higher-level\n    features.\n    -   And, importantly, is trainable many, many layers deep\n\n![img](convolve.png)\n\nReference: [http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### What is the Network Learning?\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   In general a difficult question to answer\n-   Here, Zeiler and Fergus (2013) took a trained network and *optimized\n    the input* to activate particular nodes to give an idea\n    -   Start with noise, then GD on the input, optimizing the node activation\n\n![img](network_layers.png)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Reshaping data for Keras\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Convolution of this type in Keras is provided by the `Conv2D` layer\n-   `Conv2D` requires passing an array of *width x height x channels*\n    -   Where channels might represent colors of an image\n-   We have black and white images so we'll just reshape it into the\n    required form with a single channel.\n-   We plot the image just check show the shaping is correct\n\n    x_train_dense = x_train.reshape((len(x_train), 28,28,1))\n    x_test_dense = x_test.reshape((len(x_test), 28,28,1))\n    \n    plt.clf()\n    plt.imshow(x_train_dense[0,:,:,0], cmap=\"gray\")\n    F = plt.gcf(); F.set_size_inches((2,2)); plt.savefig(\"testimg.png\");\n\n[]()\n\n![img](testimg.png)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Building a Convolutional Neural Network in Keras\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Now, lets build a convolutional neural network!\n-   Generally, `Conv2D` will be stacked on top of each other with\n    `MaxPooling2D` layers and learn edge detection at lower layers and\n    higher level feature extraction in subsequent layers.\n-   But just to show how to use them in keras, we'll just create one\n    convolution layer with 32 filters, then `Flatten` it into a 1D array\n    and pass it into a `Dense` hidden layer before the output.\n-   We can set the `kernel_size` (*m x n* size of the filter), and the number of filters used\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Building a Convolutional Neural Network in Keras\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   We can set the `kernel_size` (*m x n* size of the filter), and the number of filters used\n\n    model = Sequential()\n    \n    model.add(Conv2D(32, kernel_size=(3,3),input_shape=(28,28,1)))\n    model.add(Activation('relu'))\n    model.add(Flatten())\n    model.add(Dense(128))\n    model.add(Activation('sigmoid'))\n    model.add(Dense(10))\n    model.add(Activation('softmax'))\n    \n    model.compile(optimizer='adam', \n                  loss='categorical_crossentropy', \n                  metrics=['accuracy'])\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Training\n\n"]},{"cell_type":"markdown","metadata":{},"source":["And train the model. This is already starting to get to the point\nwhere a GPU would be extremely helpful!\n\n    model.fit(x_train_dense, y_train_enc, epochs=4, verbose=1)\n\n    Epoch 1/4\n    60000/60000 [==============================] - 65s - loss: 0.4544 - acc: 0.8825    \n    Epoch 2/4\n    60000/60000 [==============================] - 70s - loss: 0.1745 - acc: 0.9493    \n    Epoch 3/4\n    60000/60000 [==============================] - 68s - loss: 0.1369 - acc: 0.9591    \n    Epoch 4/4\n    60000/60000 [==============================] - 69s - loss: 0.1227 - acc: 0.9634    \n    <keras.callbacks.History object at 0x11d742390>\n\n    loss, accuracy = model.evaluate(x_test_dense, y_test_enc, verbose=0)\n    print(\"Loss={:.3f}\\nAccuracy = {:.3f}\".format(loss, accuracy))\n\n    Loss=0.117\n    Accuracy = 0.964\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Realistic Networks\n\n"]},{"cell_type":"markdown","metadata":{},"source":["![img](vgg16.png)\n\n-   Example of a real network used for image classification, VGG-16\n-   Typically, networks consist of several convolution layers following\n    by max pooling layers (take the max from a 2x2 square)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["## GAN\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### A Convolution GAN\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   The idea is to train two adverserial networks,\n    -   One is trying to create images equivalent to the MNIST dataset\n        -   Given an input of noise, the *latent space*\n    -   The other trying to label the images as either from the dataset or\n        fake\n        -   Fake = generated by the opposing dataset\n\n![img](Gan.png)\n\n-   References:\n    -   \\scriptsize For more on GANs and their uses: [https://arxiv.org/pdf/1701.00160.pdf](https://arxiv.org/pdf/1701.00160.pdf)\n    -   \\scriptsize Code based on: [https://github.com/jacobgil/keras-dcgan](https://github.com/jacobgil/keras-dcgan)\n    -   \\scriptsize Some tricks for training GANs [https://github.com/soumith/ganhacks](https://github.com/soumith/ganhacks)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Idea: Image generator network\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   We start with the image generation network\n-   Essentially a image classifier in reverse.\n-   The top layer is for high-level feature inputs which we'll randomly set during the training.\n-   We then pass through Dense layers and then reshape into a *7 x 7 x\n    channels* image-style layer.\n-   We `Upsampling2D` and pass through convolutional filters until the\n    last layer which outputs a *28x28x1* image as expected of an MNIST\n    greyscale image.\n    -   Essentially we're *adding* features as we go up, instead of\n        *extracting* features as we go down\n-   `BatchNormalization` is a technique to improve the network stability\n    by providing the next layer inputs with zero mean and unit variance\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Generator\n\n"]},{"cell_type":"markdown","metadata":{},"source":["    # Complete code for the generator model\n    nfeatures = 100\n    \n    generate = Sequential()\n    generate.add(Dense(1024, input_dim=nfeatures))\n    generate.add(Activation('tanh'))\n    generate.add(Dense(128*7*7))\n    generate.add(BatchNormalization())\n    generate.add(Activation('tanh'))\n    generate.add(Reshape((7, 7, 128)))\n    generate.add(UpSampling2D(size=(2,2)))\n    generate.add(Conv2D(64, (5,5), padding='same'))\n    generate.add(Activation('tanh'))\n    generate.add(UpSampling2D(size=(2,2)))\n    generate.add(Conv2D(1, (5, 5), padding='same'))\n    generate.add(Activation('sigmoid'))\n    generate.compile(loss=\"binary_crossentropy\", optimizer=\"SGD\")\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Generator Test\n\n"]},{"cell_type":"markdown","metadata":{},"source":["Now, just to check everythings put together properly, randomly pass\nsome data through the network and check we get image outputs as\nexpected.\n\n    nim = 25\n    pred = generate.predict(np.random.uniform(0, 1, (nim,nfeatures)))\n    \n    plt.clf()\n    for i in range(nim):\n        plt.subplot(np.sqrt(nim),np.sqrt(nim),i+1)\n        plt.imshow(pred[i,:,:,0], cmap='gray')\n    \n    pred[0].shape, np.average(pred[0])\n    F = plt.gcf(); F.set_size_inches((10,10))\n    plt.savefig(\"genimg_no.png\")\n\n[]()\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Example images, pre-training\n\n"]},{"cell_type":"markdown","metadata":{},"source":["![img](genimg_no.png)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Discriminator\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Next, we create the discriminating network, with an image input\n-   As for classification, we have a convolutional layer attached to Dense layers.\n-   For the output, we now have a single sigmoid with interpretation:\n    -   0: The network thinks its definitely a generated image\n    -   1: The network thinks its definitely a real MNIST dataset image\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Discriminator\n\n"]},{"cell_type":"markdown","metadata":{},"source":["    # Complete code for the discriminator network\n    discr = Sequential()\n    discr.add(Conv2D(64, (5,5), input_shape=(28,28,1), padding='same'))\n    discr.add(Activation('tanh'))\n    discr.add(MaxPooling2D((2,2)))\n    discr.add(Conv2D(128, (5,5)))\n    discr.add(Activation('tanh'))\n    discr.add(MaxPooling2D((2,2)))\n    discr.add(Dropout(0.5))\n    discr.add(Flatten())\n    discr.add(Dense(1024))\n    discr.add(Activation('tanh'))\n    discr.add(Dense(1))\n    discr.add(Activation('sigmoid'))\n    discr.compile(loss='binary_crossentropy', \n                  optimizer=SGD(lr=0.0005, momentum=0.9, \n                                nesterov=True))\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Test the discriminator\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Test the network with a few MNIST images and some random images.\n-   Since the network isn't trained we don't yet expect any differences\n    in the output.\n\n    x_prepred = np.concatenate(\n       [x_train[:5,:,:].reshape(5,28,28,1) / 256., \n        np.random.uniform(0, 1, (5, 28, 28, 1))], axis=0)\n    discr.predict(x_prepred)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### GAN\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Now we set up a network which will be used to train the generation\n    network.\n-   Keras allows us to simply add the models we just created\n    together into a Sequential like they were ordinary layers.\n-   So, we feed the generator output into the discriminator input and\n    set up an optimizer which will try to drive the generator to produce\n    MNIST-like images (i.e. to fool the discriminator).\n-   Keras allows us to turn layer training on and off through the\n    \"trainable\" variable attached to a layer, so when we train the\n    generator we can easily turn training for the discriminator off.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Setup GAN\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Using Keras, we can simply add the generator and discriminator\n    sub-networks into a new, combined network, similarly to any other\n    layer!\n-   We can also simply tell it to turn off training the discriminator\n    weights when we are optimizing the generator!\n\n    gen_discr = Sequential()\n    gen_discr.add(generate)\n    discr.trainable = False\n    gen_discr.add(discr)\n    gen_discr.compile(loss='binary_crossentropy', \n                      optimizer=SGD(lr=0.0005, momentum=0.9, \n                                    nesterov=True),\n                      metrics=['accuracy'])\n    discr.trainable = True\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Training the GAN\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Finally, we have the actual training\n-   Here, we setup the batches ourselves and alternate between training\n    the discriminator and generator\n    -   `model.train_on_batch`\n    -   This was previously put together by Keras itself\n-   We start by taking a batch of MNIST images (labeled 1), and\n    generator images (labeled 0) and run a training batch on the\n    discriminator network\n-   Then, we turn off training off the discriminator and run training on\n    the generator+discriminator network with random high-level feature\n    inputs to the generator\n-   We try to drive all the outputs to 1, i.e. train the generator to\n    more MNIST-like images (as according to the discriminator network)\n-   Last remark: we are saving the networks after each epoch with\n    `model.save`\n    -   Load with `keras.models.load_model`\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Training the GAN\n\n"]},{"cell_type":"markdown","metadata":{},"source":["    batch_size = 100\n    n_epochs = 10\n    print_every_nth_epoch = 50\n    x_tru_all = x_train.reshape(len(x_train), 28, 28, 1) / 256.\n    \n    zeros = np.array([0]*batch_size)\n    ones = np.array([1]*batch_size)\n    oneszeros = np.array([1]*batch_size + [0]*batch_size)\n    \n    losses_d = []\n    losses_g = []\n    for epoch in range(n_epochs):\n        print (\"Epoch\", epoch)\n        discr.save(\"/discr-\"+str(epoch))\n        generate.save(\"/generate-\"+str(epoch))\n        for i in range(0, len(x_train), batch_size):\n            x_gen = generate.predict(np.random.uniform(0, 1, (batch_size, nfeatures)))\n            x_tru = x_tru_all[i:i+batch_size]\n            # Train the discriminator by taking example MNIST and generator-produced images\n            discr.trainable=True\n            loss_d = discr.train_on_batch(np.concatenate([x_tru, x_gen], axis=0), oneszeros)\n            # Now, turn discriminator training off, so we can train the generator\n            discr.trainable=False\n            loss_g = gen_discr.train_on_batch(np.random.uniform(0, 1, (batch_size, nfeatures)), ones)\n            if i % (print_every_nth_epoch*batch_size) == 0:\n                print (i / batch_size, \"discr\", loss_d, \"--\", \"gen\", loss_g[0], \"( acc.\", loss_g[1], \")\")\n            losses_g.append(loss_g)\n            losses_d.append(loss_d)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Checking results\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Lets see how we did, lets just generate a bunch of images\n\n    nim = 25\n    pred = generate.predict(np.random.uniform(0, 1, (nim,nfeatures)))\n    \n    plt.clf()\n    for i in range(nim):\n        plt.subplot(np.sqrt(nim),np.sqrt(nim),i+1)\n        plt.imshow(pred[i,:,:,0], cmap='gray')\n    \n    pred[0].shape, np.average(pred[0])\n    F = plt.gcf(); F.set_size_inches((10,10)); plt.savefig(\"genimg_after.png\"); \"genimg_after.png\"\n\n[]()\n\n![img](genimg_after40.png)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Good images\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Whats the \"best\" being produced by the GAN?\n-   Only accept above 0.9 from discriminator\n\n    nim = 25\n    target = .9\n    \n    plt.clf()\n    for i in range(nim):\n        best = 0; pred=None\n        while best < target:\n            pred = generate.predict(np.random.uniform(0, 1, (1,nfeatures)))\n            best = discr.predict(pred)[0][0]\n        plt.subplot(np.sqrt(nim),np.sqrt(nim),i+1)\n        plt.imshow(pred[0,:,:,0], cmap='gray')\n    \n    pred[0].shape, np.average(pred[0])\n    F = plt.gcf(); F.set_size_inches((10,10)); plt.savefig(\"genimg40_best.9.png\"); \"genimg40_best.9.png\"\n\n[]()\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Good Images\n\n"]},{"cell_type":"markdown","metadata":{},"source":["![img](genimg40_best.9.png)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Bad images\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Whats the \"worst\" being produced by the GAN?\n-   Only accept below 0.1 from discriminator\n\n    nim = 25\n    target = .1\n    \n    plt.clf()\n    for i in range(nim):\n        best = 1; pred=None\n        while best > target:\n            pred = generate.predict(np.random.uniform(0, 1, (1,nfeatures)))\n            best = discr.predict(pred)[0][0]\n        plt.subplot(np.sqrt(nim),np.sqrt(nim),i+1)\n        plt.imshow(pred[0,:,:,0], cmap='gray')\n    \n    pred[0].shape, np.average(pred[0])\n    F = plt.gcf(); F.set_size_inches((10,10)); plt.savefig(\"genimg40_worst.1.png\"); \"genimg40_worst.1.png\"\n\n[]()\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Bad images\n\n"]},{"cell_type":"markdown","metadata":{},"source":["![img](genimg40_worst.1.png)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Extensions\n\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Try different networks, what works well, what fails badly?\n-   Add another set of inputs hot-one encoding the number you want to\n    generate,\n    -   The discriminator will need to say which number it believes its\n        seeing as well as how likely it is to be real\n    -   The generator will need to train with the number output as a loss\n        also\n-   Some further ideas on the next pages, work in progress code :-)\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Train requiring GAN to also output the correct number\n\n"]},{"cell_type":"markdown","metadata":{},"source":["    nfeatures = 100\n    \n    generate = Sequential()\n    generate.add(Dense(1024, input_dim=(nfeatures + 10)))\n    generate.add(Activation('tanh'))\n    generate.add(Dense(128*7*7))\n    generate.add(BatchNormalization())\n    generate.add(Activation('tanh'))\n    generate.add(Reshape((7, 7, 128)))\n    generate.add(UpSampling2D(size=(2,2)))\n    generate.add(Conv2D(64, (5,5), padding='same'))\n    generate.add(Activation('tanh'))\n    generate.add(UpSampling2D(size=(2,2)))\n    generate.add(Conv2D(1, (5, 5), padding='same'))\n    generate.add(Activation('sigmoid'))\n    generate.compile(loss=\"binary_crossentropy\", optimizer=\"SGD\")\n\n[]()\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Create the Discriminator\n\n"]},{"cell_type":"markdown","metadata":{},"source":["    \n    discr = Sequential()\n    discr.add(Conv2D(128, (5,5), input_shape=(28,28,1), padding='same'))\n    discr.add(Activation('relu'))\n    discr.add(MaxPooling2D((2,2)))\n    discr.add(Conv2D(256, (5,5)))\n    discr.add(Activation('relu'))\n    discr.add(MaxPooling2D((2,2)))\n    discr.add(Dropout(0.5))\n    discr.add(Flatten())\n    discr.add(Dense(1024))\n    discr.add(Activation('tanh'))\n    discr.add(Dense(11))  # 1 for real or fake, then 10 for which number\n    discr.add(Activation('sigmoid'))\n    discr.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.0005, momentum=0.9, nesterov=True),\n                  metrics=['accuracy'])\n\n[]()\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Create the combined network\n\n"]},{"cell_type":"markdown","metadata":{},"source":["    \n    gen_discr = Sequential()\n    gen_discr.add(generate)\n    discr.trainable = False\n    gen_discr.add(discr)\n    gen_discr.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.0005, momentum=0.9, nesterov=True),\n                      # optimizer='adam',\n                      metrics=['accuracy'])\n    discr.trainable = True\n    \n    batch_size = 100\n    n_epochs = 50\n    print_every_nth_epoch = 50\n    x_tru_all = x_train.reshape(len(x_train), 28, 28, 1) / 256.\n    \n    zeros = np.array([0]*batch_size)\n    ones = np.array([1]*batch_size)\n    oneszeros = np.array([1]*batch_size + [0]*batch_size)\n\n[]()\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Pre-train the discriminator on the (untrained) generator output and real MNIST\n\n"]},{"cell_type":"markdown","metadata":{},"source":["    # pre train the gan to be able to distinguish numbers\n    pre_losses_d = []\n    for epoch in range(5):\n        print (\"Epoch\", epoch)\n        for i in range(0, len(x_train), batch_size):\n            one_hot_gen = np.eye(10)[np.random.random_integers(0, 9, size=(batch_size,))]\n            x_inp = np.concatenate([np.random.uniform(0, 1, (batch_size, nfeatures)), one_hot_gen], axis=1)\n            x_gen = generate.predict(x_inp)\n            x_tru = x_tru_all[i:i+batch_size]\n            y_tru = y_train_enc[i:i+batch_size]\n            discr.trainable = True\n            for_d_tru = np.concatenate([np.zeros((batch_size,1)), y_tru], axis=1)\n            for_d_gen = np.concatenate([np.ones((batch_size,1)), np.zeros((batch_size,10))], axis=1)\n            loss_d = discr.train_on_batch(np.concatenate([x_tru, x_gen], axis=0), \n                                          np.concatenate([for_d_tru, for_d_gen], axis=0))\n            if i % (print_every_nth_epoch*batch_size) == 0:\n                print (i / batch_size, \"discr\", loss_d)\n            pre_losses_d.append(loss_d)\n    \n    loss, accuracy = discr.evaluate(x_test_dense, \n                                    np.concatenate([np.zeros((len(y_test_enc),1)), y_test_enc], axis=1), verbose=0)\n    print(\"Loss={:.3f}\\nAccuracy = {:.3f}\".format(loss, accuracy))\n\n[]()\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Train the generator and discriminator together\n\n"]},{"cell_type":"markdown","metadata":{},"source":["    losses_d = []\n    losses_g = []\n    for epoch in range(n_epochs):\n        print (\"Epoch\", epoch)\n        discr.save(\"discr-num-\"+str(epoch))\n        generate.save(\"generate-num-\"+str(epoch))\n        for i in range(0, len(x_train), batch_size):\n            one_hot_gen = np.eye(10)[np.random.random_integers(0, 9, size=(batch_size,))]\n            x_inp = np.concatenate([np.random.uniform(0, 1, (batch_size, nfeatures)), one_hot_gen], axis=1)\n            x_gen = generate.predict(x_inp)\n            x_tru = x_tru_all[i:i+batch_size]\n            y_tru = y_train_enc[i:i+batch_size]\n            discr.trainable = True\n            for_d_tru = np.concatenate([np.zeros((batch_size,1)), y_tru], axis=1)\n            for_d_gen = np.concatenate([np.ones((batch_size,1)), np.zeros((batch_size,10))], axis=1)\n            loss_d = discr.train_on_batch(np.concatenate([x_tru, x_gen], axis=0), \n                                          np.concatenate([for_d_tru, for_d_gen], axis=0))\n            discr.trainable=False\n            for_g = np.concatenate([np.zeros((batch_size,1)), one_hot_gen], axis=1)\n            new_inp_g = np.concatenate([np.random.uniform(0, 1, (batch_size, nfeatures)), one_hot_gen], axis=1)\n            loss_g = gen_discr.train_on_batch(new_inp_g, for_g)\n            if i % (print_every_nth_epoch*batch_size) == 0:\n                print (i / batch_size, \"discr\", loss_d, \"--\", \"gen\", loss_g[0], \"( acc.\", loss_g[1], \")\")\n            losses_g.append(loss_g)\n            losses_d.append(loss_d)\n    \n    print (\"done\")\n\n[]()\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Check the output of the labelled GAN\n\n"]},{"cell_type":"markdown","metadata":{},"source":["    # generate = tf.keras.models.load_model('generate-num-41')\n    \n    nim = 25\n    numb = 1\n    pred = generate.predict(np.concatenate([np.random.uniform(0, 1, (nim,nfeatures)), np.eye(10)[[numb,]*nim] ], axis=1))\n    \n    plt.clf()\n    for i in range(nim):\n        plt.subplot(np.sqrt(nim),np.sqrt(nim),i+1)\n        plt.imshow(pred[i,:,:,0], cmap='gray')\n    \n    pred[0].shape, np.average(pred[0])\n    F = plt.gcf(); F.set_size_inches((10,10)); plt.savefig(\"gen-num-img_after-%d.png\" % numb); \"gen-num-img_after-%d.png\" % numb\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Some examples from labelled GAN\n\n"]},{"cell_type":"markdown","metadata":{},"source":["![img](gen-num-img_after-4.png)\n\n![img](gen-num-img_after-5.png)\n\n"]}],"metadata":[["org"],null,null],"nbformat":4,"nbformat_minor":0}